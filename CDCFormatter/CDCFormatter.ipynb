{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import OutcomesGen as og\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from time import sleep\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDCFormatter\n",
    "\n",
    "This notebook processes experimental exposed by subpopulation and day data to generate full outcome data across ages, geographies, and disease states:\n",
    "\n",
    "* Disease state transitions are loaded from *FluTransitionsP3.xlsx*\n",
    "* Breakdown of ages by region is loaded from *../PatchSim-Experiments-Gen/FixedUSAPop.patchsim*\n",
    "* Membership of geographies by counties' first 2 FIPS digits is loaded from *SubsetRegionFIPS.csv*\n",
    "* CDC output templates are loaded from *templates/{experiment-outcome}.csv*\n",
    "* Experimental parameters are loaded from *../PatchSim-Experiments-Gen/experiments/{experiment}/MetaData.csv*\n",
    "* The method **runAllOutcomes()** uses said metadata to load experiment scenario outputs, stochastically transition exposures between disease states, break down disease states by age and geography, and format the resulting curves in accordance to the CDC templates\n",
    "* Generated data and figures are saved to the *output* and *figures* subdirectories for each scenario in *../PatchSim-Experiments-Gen/experiments/{experiment}/* \n",
    "\n",
    "Note: If **runAllOutcomes()** is run with the parameter **skipFinished=True**, then outcome processing will skip scenario subdirectories within experiments which contain an output directory. This allows for multiple instances of the notebook may be ran simultaneously without interferenceto distribute outcome processing workloads across machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageKey = {'all':'Overall',\n",
    "           'p':'0-4 years',\n",
    "           's':'5-17 years',\n",
    "           'a':'18-49 years',\n",
    "           'o':'50-64 years',\n",
    "           'g':'65+ years'}\n",
    "\n",
    "\n",
    "\n",
    "def getRegionPopSizes(ref='../PatchSim-Experiments-Gen/FixedUSAPop.patchsim'):\n",
    "    \"\"\"Loads region pop size data\"\"\"\n",
    "    sizeDf = pd.read_csv(ref,\n",
    "                         sep=' ',\n",
    "                         names=['population','popsize'])\n",
    "    sizeDf.loc[:,'fips'] = sizeDf.population.str[:-1]\n",
    "    sizeDf.loc[:,'age_group'] = sizeDf.population.str[-1]\n",
    "    sizeDf.set_index(['population'],inplace=True)\n",
    "\n",
    "    \n",
    "    regionPopSizes = []\n",
    "    \n",
    "    for region,fips in regions.items():\n",
    "        selectedPops = sizeDf.index.tolist()\n",
    "        if region != 'US National':\n",
    "            selectedPops = [population for population in selectedPops if population[:2] in fips]\n",
    "        regionDf = sizeDf.loc[selectedPops,:].copy(deep=True)\n",
    "        cohortSizes = dict(regionDf.groupby(['age_group']).popsize.sum())\n",
    "        cohortSizes['all'] = regionDf.popsize.sum()\n",
    "        regionPopSizes.append({**{'region':region},\n",
    "                               **{'all':regionDf.popsize.sum()},\n",
    "                               **cohortSizes})\n",
    "        \n",
    "    regionPopSizes = pd.DataFrame(regionPopSizes)    \n",
    "    regionPopSizes.set_index(['region'],inplace=True)\n",
    "        \n",
    "        \n",
    "    return regionPopSizes\n",
    "        \n",
    "\n",
    "\n",
    "def getRegions():\n",
    "    \"\"\"Get population regions\"\"\"\n",
    "    df = pd.read_csv('SubsetRegionFIPS.csv')\n",
    "    regions = {region:set(members.split()) for region, members in zip(df.region,df.members)}\n",
    "    return regions\n",
    "    \n",
    "regions = getRegions()\n",
    "regionPopSizes = getRegionPopSizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>a</th>\n",
       "      <th>g</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US National</th>\n",
       "      <td>296710391</td>\n",
       "      <td>119404302.0</td>\n",
       "      <td>45765003.0</td>\n",
       "      <td>61929159.0</td>\n",
       "      <td>17766046.0</td>\n",
       "      <td>51845881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHS Region 1</th>\n",
       "      <td>13718580</td>\n",
       "      <td>5356659.0</td>\n",
       "      <td>2289674.0</td>\n",
       "      <td>3160893.0</td>\n",
       "      <td>708510.0</td>\n",
       "      <td>2202844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHS Region 2</th>\n",
       "      <td>26527179</td>\n",
       "      <td>10808654.0</td>\n",
       "      <td>4151408.0</td>\n",
       "      <td>5694207.0</td>\n",
       "      <td>1486332.0</td>\n",
       "      <td>4386578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHS Region 3</th>\n",
       "      <td>28361274</td>\n",
       "      <td>11241648.0</td>\n",
       "      <td>4615006.0</td>\n",
       "      <td>6227278.0</td>\n",
       "      <td>1610763.0</td>\n",
       "      <td>4666579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHS Region 4</th>\n",
       "      <td>58234780</td>\n",
       "      <td>22730924.0</td>\n",
       "      <td>9935548.0</td>\n",
       "      <td>12352160.0</td>\n",
       "      <td>3341164.0</td>\n",
       "      <td>9874984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>5527167</td>\n",
       "      <td>2142535.0</td>\n",
       "      <td>871148.0</td>\n",
       "      <td>1232873.0</td>\n",
       "      <td>320531.0</td>\n",
       "      <td>960080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>551298</td>\n",
       "      <td>214056.0</td>\n",
       "      <td>83061.0</td>\n",
       "      <td>119598.0</td>\n",
       "      <td>36779.0</td>\n",
       "      <td>97804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>570286</td>\n",
       "      <td>295960.0</td>\n",
       "      <td>75013.0</td>\n",
       "      <td>100099.0</td>\n",
       "      <td>31943.0</td>\n",
       "      <td>67271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgin Islands</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            all            a           g           o  \\\n",
       "region                                                                 \n",
       "US National           296710391  119404302.0  45765003.0  61929159.0   \n",
       "HHS Region 1           13718580    5356659.0   2289674.0   3160893.0   \n",
       "HHS Region 2           26527179   10808654.0   4151408.0   5694207.0   \n",
       "HHS Region 3           28361274   11241648.0   4615006.0   6227278.0   \n",
       "HHS Region 4           58234780   22730924.0   9935548.0  12352160.0   \n",
       "...                         ...          ...         ...         ...   \n",
       "Wisconsin               5527167    2142535.0    871148.0   1232873.0   \n",
       "Wyoming                  551298     214056.0     83061.0    119598.0   \n",
       "District of Columbia     570286     295960.0     75013.0    100099.0   \n",
       "Puerto Rico                   0          NaN         NaN         NaN   \n",
       "Virgin Islands                0          NaN         NaN         NaN   \n",
       "\n",
       "                               p           s  \n",
       "region                                        \n",
       "US National           17766046.0  51845881.0  \n",
       "HHS Region 1            708510.0   2202844.0  \n",
       "HHS Region 2           1486332.0   4386578.0  \n",
       "HHS Region 3           1610763.0   4666579.0  \n",
       "HHS Region 4           3341164.0   9874984.0  \n",
       "...                          ...         ...  \n",
       "Wisconsin               320531.0    960080.0  \n",
       "Wyoming                  36779.0     97804.0  \n",
       "District of Columbia     31943.0     67271.0  \n",
       "Puerto Rico                  NaN         NaN  \n",
       "Virgin Islands               NaN         NaN  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionPopSizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data & template loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemplate(ref='templates/HP09_SymIllness_NEU.csv'):\n",
    "    \"\"\"Loads a CDC output format template\"\"\"\n",
    "    template = pd.read_csv(ref)\n",
    "    bins = template.Bin.unique()\n",
    "    cmlBins = template.Bin_cml.unique()\n",
    "    \n",
    "    getRange = lambda x: [float(i) for i in x.replace('[','').replace(']','').replace(')','').replace('Inf','9999').split('-')]\n",
    "    ranges = {i:getRange(i) for i in bins if i.startswith('[')}\n",
    "    cmlRanges = {i:getRange(i) for i in cmlBins if i.startswith('[')}\n",
    "    \n",
    "    percs = {'sm.mean':np.mean,\n",
    "            'sm.median':np.median,\n",
    "            'sm.perc2p5':lambda x: np.percentile(x,2.5),\n",
    "            'sm.perc5':lambda x: np.percentile(x,5),\n",
    "            'sm.perc25':lambda x: np.percentile(x,25),\n",
    "            'sm.perc75':lambda x: np.percentile(x,75),\n",
    "            'sm.perc95':lambda x: np.percentile(x,95),\n",
    "            'sm.perc97p5':lambda x: np.percentile(x,97.5),\n",
    "            'sm.peak':np.max}\n",
    "    \n",
    "    return ranges, cmlRanges, percs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepOne(args):\n",
    "    \"\"\"Worker subprocess for prepRuns()\"\"\"\n",
    "    (splitRun,sample,scenario,approximateAges,transitionsRef,scalers) = args\n",
    "    print(\"Starting sample\",sample)\n",
    "    splitRun = splitRun.drop(['sample'],axis=1).set_index('id').T\n",
    "    splitRun.index = splitRun.index.astype('int32')\n",
    "    splitRun.sort_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    outcomes = og.getCOVIDOutcomes(splitRun,\n",
    "                                    scenario,\n",
    "                                    ignore=set(),\n",
    "                                    dwellFields=set(),\n",
    "                                    approximateAges=False,\n",
    "                                    mergeAges=False,\n",
    "                                    mergeStates=True,\n",
    "                                    saveResults=False,\n",
    "                                    noThreading=True,\n",
    "                                    verbose=False,\n",
    "                                    flowsRef=transitionsRef,\n",
    "                                    scalers=scalers)\n",
    "    \n",
    "    outcomes = og.autoMerge(outcomes,toForce={'Hosp',\n",
    "                                              'Isymp',\n",
    "                                              'AVDoses',\n",
    "                                              'Vent',\n",
    "                                              'Death'})\n",
    "\n",
    "    toKeep = {'E',\n",
    "              'Hosp',\n",
    "              'AVDoses',\n",
    "              'Isymp',\n",
    "              'Vent',\n",
    "              'Death'}\n",
    "    \n",
    "    outcomes = {key:value for key,value in outcomes.items() if key in toKeep}\n",
    "    \n",
    "    selectedRows = splitRun.index\n",
    "    for key,compartmentDf in outcomes.items():\n",
    "        compartmentDf = compartmentDf.loc[selectedRows,:]\n",
    "        compartmentDf.index = 'Week'+(compartmentDf.index.astype(int)/7+1).astype(int).astype(str).str.zfill(2)\n",
    "        compartmentDf = compartmentDf.groupby(compartmentDf.index).sum().sort_index()\n",
    "        compartmentDf.index = [i.replace('Week0','Week') for i in compartmentDf.index]\n",
    "        outcomes[key] = compartmentDf\n",
    " \n",
    "    return outcomes\n",
    "\n",
    "\n",
    "def prepRuns(ref,\n",
    "            threads=5,\n",
    "            scenario='default',\n",
    "            approximateAges=False,\n",
    "            scalers='null',\n",
    "            transitionsRef='FluTransitionsP3.xlsx'):\n",
    "    \"\"\"Generates disease state data from processing of simulation output through transition model\"\"\"\n",
    "    mergedData = pd.read_csv(ref)\n",
    "    samples = sorted(list(mergedData['sample'].unique()))\n",
    "    \n",
    "    splitRun = mergedData[mergedData['sample'] == 1]\n",
    "    splitRun = splitRun.drop(['sample'],axis=1).set_index('id')\n",
    "    print(\"Loading transitions from\",transitionsRef)\n",
    "    og.getTransitions(transitionsRef,scenario=scenario)\n",
    "    \n",
    "    print(\"Loading %s, found %s samples\" % (ref,len(samples)))\n",
    "    toRun = [(mergedData[mergedData['sample'] == sample].copy(deep=True),\n",
    "              sample,\n",
    "              scenario,\n",
    "              approximateAges,\n",
    "              transitionsRef,\n",
    "              scalers) for sample in samples]\n",
    "    \n",
    "    \n",
    "    if threads == 1:\n",
    "        splitRuns = [prepOne(i) for i in toRun]\n",
    "    else:\n",
    "        p = Pool(threads)\n",
    "        splitRuns = p.map(prepOne,toRun)\n",
    "        p.close()\n",
    "        p.join()\n",
    "    \n",
    "    print(\"Single experiment prep done.\")\n",
    "    return splitRuns\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatter execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRawSpread(dfIn,\n",
    "                  outcome,\n",
    "                  title='',\n",
    "                  yLabel='',\n",
    "                  figFile=''):\n",
    "    \"\"\"Debugging method to plot curves before formatting\"\"\"\n",
    "    \n",
    "    color = {'E':'seagreen',\n",
    "                'Isymp':'orange',\n",
    "                'Hosp':'orangered',\n",
    "                'Vent':'darkred',\n",
    "                'Death':'black',\n",
    "                'AVDoses':'blueviolet'}[outcome]\n",
    "    df = dfIn.copy(deep=True)\n",
    "    df.loc[:,'Week of simulation'] = df.index\n",
    "    df = pd.melt(df,id_vars='Week of simulation',var_name='run')\n",
    "    df['Week of simulation'] = df['Week of simulation'].str.replace(\"Week\",'').astype(int)\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    sns.lineplot(x=\"Week of simulation\",\n",
    "                 y=\"value\",\n",
    "                 data=df,\n",
    "                 ax=ax,\n",
    "                 color=color)\n",
    "    ax.set_ylabel(yLabel)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if figFile != '':\n",
    "        plt.savefig(figFile,bbox_inches='tight')\n",
    "    plt.close()\n",
    "        \n",
    "\n",
    "def binCmlCurves(cmlRanges,percs,percsByGeo):\n",
    "    \"\"\"Bins cumulative curves\"\"\"\n",
    "    nRuns = len(percsByGeo)\n",
    "    cmlRangeBins = np.array([i[0] for i in cmlRanges.values()])\n",
    "    cmlRangeNames = list(cmlRanges.keys())\n",
    "    \n",
    "    cmlRangesDf = pd.DataFrame(0.,\n",
    "                               index=cmlRanges.keys(),\n",
    "                               columns=['cml'])\n",
    "    \n",
    "    cmlInfs = [run.sum() for run in percsByGeo]\n",
    "\n",
    "    inds = [cmlRangeNames[i[0]] for i in list(np.digitize(cmlInfs,cmlRangeBins)-1)]\n",
    "    for ind in inds:\n",
    "        cmlRangesDf.at[ind,'cml'] += 1\n",
    "    cmlRangesDf['cml'] = cmlRangesDf['cml'] / nRuns\n",
    "        \n",
    "    percRangesDf = pd.DataFrame(0.,\n",
    "                               index=percs.keys(),\n",
    "                               columns=['cml'])\n",
    "    \n",
    "    mergedCml = pd.concat([cmlRangesDf,percRangesDf])\n",
    "    \n",
    "    return mergedCml\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "def formatEntry(runDataIn,\n",
    "                outcome,\n",
    "                ageCohort='all',\n",
    "                showPlot=True,\n",
    "                template='templates/HP09_SymIllness_NEU.csv',\n",
    "                dirOut='test',\n",
    "                fileName='test',\n",
    "                selectedGeo='US National',\n",
    "                plotRaw=False,\n",
    "                plotCmlSpread=False,\n",
    "                units=100):\n",
    "    \"\"\"Generates outcome data and figures for one age cohort, disease outcome, and geography\"\"\"\n",
    "    \n",
    "    runData = [outcomesDict[outcome].copy(deep=True) for outcomesDict in runDataIn]\n",
    "    \n",
    "    if ageCohort == 'all':\n",
    "        selectedPops = list(runData[0].columns)\n",
    "    else:\n",
    "        selectedPops = [i for i in runData[0].columns if i.endswith(ageCohort)]\n",
    "        \n",
    "    if selectedGeo != 'US National':\n",
    "        selectedPops = [i for i in selectedPops if i[:2] in regions[selectedGeo]]\n",
    "\n",
    "    regionAbbrev = selectedGeo.replace(' ','')\n",
    "\n",
    "    geoMapper = {i:selectedGeo for i in runData[0].columns}    \n",
    "        \n",
    "    runData = [run[selectedPops] for run in runData]\n",
    "    \n",
    "    popSize = regionPopSizes.at[selectedGeo,ageCohort]\n",
    "    print(\"Running with popsize of\",popSize)\n",
    "        \n",
    "    ranges, cmlRanges, percs = getTemplate(template)\n",
    "    geoGraphies = geoMapper.values()\n",
    "    runsByGeo = [run.rename(geoMapper,axis=1).groupby(axis=1, level=0).sum() for run in runData]\n",
    "    percsByGeo = [(units*run)/popSize for run in runsByGeo]\n",
    "    weeks = list(runData[0].index)\n",
    "    nRuns = len(runData)\n",
    "        \n",
    "    percsByWeek = pd.DataFrame(index=percs.keys(),\n",
    "                               columns=weeks)\n",
    "    rangesByWeek = pd.DataFrame(0,\n",
    "                               index=ranges.keys(),\n",
    "                               columns=weeks)\n",
    "\n",
    "    rangeBins = np.array([i[0] for i in ranges.values()])\n",
    "    rangeNames = list(ranges.keys())\n",
    "    \n",
    "    rawCurves = pd.DataFrame({i:curve.iloc[:,0] for i,curve in enumerate(percsByGeo)})\n",
    "    \n",
    "    for run in percsByGeo:\n",
    "        inds = [rangeNames[i[0]] for i in list(np.digitize(run,rangeBins)-1)]\n",
    "        for week,ind in zip(weeks,inds):\n",
    "            rangesByWeek.at[ind,week] += 1\n",
    "                        \n",
    "    rangesByWeek = rangesByWeek/nRuns\n",
    "    yUnitLabel = {100:'Percent in compartment bin',\n",
    "                 100000:'Number in compartment bin per 100k persons'}[units]\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    rangesPlotDf = rangesByWeek.copy(deep=True)\n",
    "    rangesPlotDf = rangesPlotDf[rangesPlotDf.index <= rangesPlotDf[rangesPlotDf.sum(axis=1) > 0].index[-1]]\n",
    "    \n",
    "    sns.heatmap(rangesPlotDf[::-1],\n",
    "                cmap='viridis_r',\n",
    "                ax=ax)\n",
    "    scenario = dirOut.split('/')[-2]\n",
    "    figFile = '%sfigures/%s/%s_%s_%s.png' % (dirOut,regionAbbrev,fileName,regionAbbrev,ageCohort)\n",
    "    plotTitle = 'UVA %s %s age: %s' % (scenario,selectedGeo,ageKey[ageCohort])\n",
    "\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel(yUnitLabel)\n",
    "    plt.savefig(figFile,bbox_inches='tight')\n",
    "    \n",
    "    if ageCohort == 'all':\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    if plotRaw:\n",
    "        plotRawSpread(rawCurves,\n",
    "                      outcome,\n",
    "                      title=plotTitle,\n",
    "                      figFile=figFile.replace('.png','_curves.png'),\n",
    "                      yLabel=yUnitLabel)\n",
    "    \n",
    "    for week in weeks:\n",
    "        weekValues = [float(run.at[week,selectedGeo]) for run in percsByGeo]\n",
    "        for metric,fx in percs.items():\n",
    "            percsByWeek.at[metric,week] = fx(weekValues)\n",
    "    \n",
    "\n",
    "    rangesByWeek.at[:,'Peak Magnitude'] = 0.\n",
    "    peaks = rawCurves.max(axis=0)\n",
    "    inds = [rangeNames[i] for i in list(np.digitize(peaks,rangeBins)-1)]\n",
    "    increment = 1/nRuns\n",
    "    for ind in inds:\n",
    "        rangesByWeek.at[ind,'Peak Magnitude'] += increment\n",
    "    for metric,fx in percs.items():\n",
    "        percsByWeek.at[metric,'Peak Magnitude'] = fx(peaks)\n",
    "    \n",
    "    \n",
    "    mergedTables = pd.concat([rangesByWeek,percsByWeek])\n",
    "    mergedTables.loc[:,'Bin'] = mergedTables.index\n",
    "    cmlDf = binCmlCurves(cmlRanges,percs,percsByGeo)\n",
    "    mergedTables.loc[:,'Bin_cml'] = list(cmlDf.index)\n",
    "    mergedTables.loc[:,'Cml'] = list(cmlDf['cml'])\n",
    "    mergedTables.index = range(len(mergedTables))\n",
    "    mergedTables.loc[:,'Location'] = selectedGeo\n",
    "    mergedTables.loc[:,'Agegroup'] = ageKey[ageCohort]\n",
    "    \n",
    "    \n",
    "    frontCols = ['Location','Agegroup','Bin_cml','Cml','Bin','Peak Magnitude']\n",
    "    mergedTables = mergedTables[frontCols+weeks]\n",
    "    \n",
    "    cmlPlotDf = mergedTables.iloc[:len(rangesByWeek)][['Bin_cml','Cml']].copy(deep=True)\n",
    "    cmlPlotDf.set_index(\"Bin_cml\",inplace=True)\n",
    "    cmlPlotDf = cmlPlotDf[cmlPlotDf.index <= cmlPlotDf[cmlPlotDf.Cml != 0].index[-1]]\n",
    "    cmlPlotDf = cmlPlotDf[cmlPlotDf.index >= cmlPlotDf[cmlPlotDf.Cml != 0].index[0]]\n",
    "\n",
    "    if plotCmlSpread:\n",
    "        fig,ax = plt.subplots(figsize=(10,6))\n",
    "        cmlPlotDf.Cml.plot(kind='bar',ax=ax)\n",
    "        cmlTitle = plotTitle + 'Cml Distribution'\n",
    "        cmlFile = figFile.replace('.png','_CmlDist.png')\n",
    "        plt.xlabel('Bin_cml')\n",
    "        plt.ylabel('Proportion')\n",
    "        plt.title(plotTitle)\n",
    "        plt.ylim(0,cmlPlotDf.Cml.max())\n",
    "        plt.savefig(cmlFile,bbox_inches='tight')\n",
    "\n",
    "        plt.close()\n",
    "    \n",
    "    return mergedTables, rawCurves\n",
    "\n",
    "\n",
    "\n",
    "def runAllOutcomes(metaRef,\n",
    "                   transitionsRef='FluTransitionsP3.xlsx',\n",
    "                   templatesRef='TemplateAlignmentRLV6.csv',\n",
    "                   skipFinished=True,\n",
    "                   scalers='null',\n",
    "                   dumpRaw=False,\n",
    "                   makeOutcomes=True):\n",
    "    \"\"\"Primary analysis function, parses experiment metadata to execute full outcome processing\"\"\"\n",
    "    metaDf = pd.read_csv(metaRef)\n",
    "    \n",
    "    outcomes = ['Isymp',\n",
    "                'Hosp',\n",
    "                'Vent',\n",
    "                'Death',\n",
    "                'AVDoses',]\n",
    "    \n",
    "    templates = pd.read_csv(templatesRef,index_col=0)\n",
    "        \n",
    "    for index,row in metaDf.iterrows():\n",
    "        dataFile = row['MergedOutput']\n",
    "        scenario = row['Scenario']\n",
    "        dirOut = dataFile.replace(\"MergedSamples.csv\",'outcomes/')\n",
    "        figsOut = dataFile.replace(\"MergedSamples.csv\",'figures/')\n",
    "        isFinished = len(glob(dirOut+'*_AntiviralTX_UVA.csv')) == 1\n",
    "        isStarted = os.path.exists(dirOut)\n",
    "        \n",
    "        if not isStarted or not skipFinished:\n",
    "            if not os.path.exists(dirOut):\n",
    "                os.makedirs(dirOut)\n",
    "            if not os.path.exists(figsOut):\n",
    "                os.makedirs(figsOut)\n",
    "            interventions = row['Interventions']\n",
    "            avUsed = '!AV' not in interventions\n",
    "            opScenario = {True:'av',\n",
    "                          False:'default'}[avUsed]\n",
    "            while not os.path.exists(dataFile):\n",
    "                print(\"Datafile %s not found, sleeping\" % dataFile)\n",
    "                sleep(60)\n",
    "            \n",
    "            global runsGlobal\n",
    "            runsGlobal = prepRuns(dataFile,\n",
    "                            scenario=opScenario,\n",
    "                            threads=10,\n",
    "                            transitionsRef=transitionsRef,\n",
    "                            scalers=scalers)\n",
    "            \n",
    "            if dumpRaw:\n",
    "                rawOutRef = dataFile.replace(\"MergedSamples.csv\",'RawOutcomes.pickle')\n",
    "                with open(rawOutRef,'wb') as fileOut:\n",
    "                    pickle.dump(runsGlobal,\n",
    "                                fileOut,\n",
    "                                protocol=-1)\n",
    "            if makeOutcomes:\n",
    "                for outcome in outcomes:\n",
    "                    template = templates.at[outcome,'template']\n",
    "                    fileName = templates.at[outcome,'fileOut']\n",
    "                    units = templates.at[outcome,'units']\n",
    "                    ageTables = []\n",
    "                    fileOut = '%s%s_%s_UVA.csv' % (dirOut,scenario,fileName)\n",
    "                    fileName = '%s_%s_UVA' % (scenario,fileName)\n",
    "\n",
    "                    for region in regions.keys():\n",
    "                        regionAbbrev = region.replace(' ','')\n",
    "                        regionDataDir = '%s%s/' % (dirOut,regionAbbrev)\n",
    "                        regionFigDir = '%s%s/' % (figsOut,regionAbbrev)\n",
    "                        if not os.path.exists(regionDataDir):\n",
    "                            os.makedirs(regionDataDir)\n",
    "                        if not os.path.exists(regionFigDir):\n",
    "                            os.makedirs(regionFigDir)\n",
    "\n",
    "                        ageRunArgs = []\n",
    "\n",
    "                        for age in ['all','p','s','a','o','g']:\n",
    "                            ageRunArgs.append((age,\n",
    "                                               outcome,\n",
    "                                               template,\n",
    "                                               dataFile.replace(\"MergedSamples.csv\",'/'),\n",
    "                                               fileName,\n",
    "                                               units,\n",
    "                                               region))\n",
    "\n",
    "\n",
    "                        p = Pool(6)\n",
    "                        splitRuns = p.map(formatEntrySub,ageRunArgs)\n",
    "                        p.close()\n",
    "                        p.join()\n",
    "\n",
    "                        ageTables += [i for i in splitRuns if type(i) is not str]\n",
    "                        clear_output()\n",
    "\n",
    "                    pd.concat(ageTables).to_csv(fileOut,index=False)\n",
    "\n",
    "        \n",
    "\n",
    "def formatEntrySub(args):\n",
    "    \"\"\"Subprocess to run age cohort outcome processing in parallel for a single disease state and geo\"\"\"\n",
    "    (age,outcome,template,dirOut,fileName,units,region) = args\n",
    "    regionAbbrev = region.replace(' ','')\n",
    "    \n",
    "    try:\n",
    "        mergedTables, rawCurves = formatEntry(runsGlobal,\n",
    "                                              ageCohort=age,\n",
    "                                              outcome=outcome,\n",
    "                                              showPlot=True,\n",
    "                                              template=template,\n",
    "                                              dirOut=dirOut,\n",
    "                                              fileName=fileName,\n",
    "                                              units=units,\n",
    "                                              selectedGeo=region)\n",
    "        \n",
    "        rawOut = '%soutcomes/%s/%s_%s_RawCurves.csv' % (dirOut,regionAbbrev,fileName,age)\n",
    "        rawCurves.to_csv(rawOut)\n",
    "        return mergedTables\n",
    "    except:\n",
    "        print(\"Failed for\",region,age)\n",
    "        return 'failed'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run hypothetical scenario outcome processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllOutcomes('../PatchSim-Experiments-Gen/experiments/WorkingTemplateP9_USA/MetaData.csv',\n",
    "              transitionsRef='FluTransitionsP3.xlsx',\n",
    "              templatesRef='TemplateAlignmentHPV6.csv',\n",
    "              skipFinished=True,\n",
    "              scalers='null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run 2009 scenario outcome processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runAllOutcomes('../PatchSim-Experiments-Gen/experiments/WorkingTemplateP9_USA/MetaData.csv',\n",
    "              transitionsRef='FluTransitionsP3.xlsx',\n",
    "              skipFinished=False,\n",
    "              scalers='null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-geopandas]",
   "language": "python",
   "name": "conda-env-.conda-geopandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
