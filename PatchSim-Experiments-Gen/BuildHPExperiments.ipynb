{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BuildHPExperiments\n",
    "\n",
    "This notebook parses experiment parameter files to generate ready to run STOMP-flu experiments: \n",
    "\n",
    "* Experiment scenario parameters are loaded from the passed **ExperimentSetup*.csv** file\n",
    "* Flags in each scenario link to intervention code lines within **EventLines.txt**\n",
    "* These flags are and selected code lines are then inserted into a template experiment execution script from *templates/\n",
    "* The generated run scripts and configuration files are copied to their respective directories in **experiments/{experiment}/{scenario}/**\n",
    "* Metadata of experiment parameters and file locations is written to **experiments/{experiment}/MetaData.csv**\n",
    "* A monolithic bash script to run all of the experiments as well as 4 partial bash scripts for divided workflows is written to **experiments/{experiment}/RunAll*.sh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario Script Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepScenarioEvents(source='ExperimentSetup.csv'):\n",
    "    \"\"\"Loads experiment setup and returns table with list of simulated events column\"\"\"\n",
    "    \n",
    "    script = pd.read_csv(source)\n",
    "    script = script.fillna('').astype('str')\n",
    "    script.loc[:,'Events'] = (script.Epi + ' ' + script.Interventions).str.strip().str.split(' ')\n",
    "    \n",
    "    return script\n",
    "\n",
    "\n",
    "def prepEventLines(source='EventLines.txt'):\n",
    "    \"\"\"Parses EventsLines.txt file and generates dictionary of script lines for each event\"\"\"\n",
    "    \n",
    "    with open(source) as fileIn:\n",
    "        lines = fileIn.readlines()\n",
    "        \n",
    "    lines = [line.replace('\\n','') for line in lines if line != '\\n']\n",
    "    starts = [i for i,line in enumerate(lines) if line.startswith('*')]\n",
    "    ends = [i-1 for i in starts[1:]+[len(lines)]]\n",
    "    names = [lines[i].replace('*','').strip() for i in starts]\n",
    "    lineRanges = {name:list(range(start+1,end+1)) for name,start,end in zip(names,starts,ends)}\n",
    "    eventLines = {name:[lines[i]+'\\n' for i in lineRange] for name,lineRange in lineRanges.items()}\n",
    "    \n",
    "    return eventLines\n",
    "\n",
    "\n",
    "def getScenarioLines(scenarioSource='ExperimentSetup.csv',\n",
    "                    eventSource='EventLines.txt'):\n",
    "    \"\"\"Generates scenario lines dict\"\"\"\n",
    "    \n",
    "    scenarioEvents = prepScenarioEvents(scenarioSource)\n",
    "    eventLines = prepEventLines(eventSource)\n",
    "    \n",
    "    scenarioEvents = {scenario:events for scenario,events in zip(scenarioEvents.Scenario,scenarioEvents.Events)}\n",
    "    scenarioLines = {scenario:[eventLines[event] for event in events] for scenario,events in scenarioEvents.items()}\n",
    "    scenarioLines = {scenario:list(chain.from_iterable(eventLines)) for scenario,eventLines in scenarioLines.items()}\n",
    "    \n",
    "    return scenarioLines, scenarioEvents\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Generator Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignPopNets(populations,networks):\n",
    "    \"\"\"Returns a dict of experiment names and matched populations and networks\"\"\"\n",
    "    \n",
    "    matched = {'USA':(populations[0],networks[0])}\n",
    "    for population in populations[1:]:\n",
    "        name = population.split('/')[-1].split('.')[0]\n",
    "        found = False\n",
    "        for network in networks[1:]:\n",
    "            if network.split('/')[-1].startswith(name):\n",
    "                matched[name] = (population,network)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(name)\n",
    "    return matched\n",
    "\n",
    "\n",
    "def prepExperiment(experimentName,\n",
    "                  population,\n",
    "                  network,\n",
    "                  templateLines,\n",
    "                  stubFile,\n",
    "                  prefixLines=[]):\n",
    "    \"\"\"Processing a template cfg file to generate a single experiment dir with patchsim script and config\"\"\"\n",
    "    \n",
    "    dirOut = 'experiments/%s/' % experimentName\n",
    "    if not os.path.exists(dirOut):\n",
    "        os.makedirs(dirOut)\n",
    "    \n",
    "    print(\"Prepping experiment in directory %s\" % experimentName)\n",
    "\n",
    "    with open('%s/config.patchsim' % dirOut,'w') as fileOut:\n",
    "        fileOut.write(''.join(templateLines))\n",
    "    \n",
    "    with open(stubFile) as stubFileIn:\n",
    "        patchSimStub = prefixLines + stubFileIn.readlines()\n",
    "    \n",
    "    with open(\"%s/RunPatchsim.py\" % dirOut,'w') as fileOut:\n",
    "        fileOut.write(''.join(patchSimStub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment generator main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepExperiments(toRun=['USA'],\n",
    "                    prefix='',\n",
    "                    template='templates/WorkingCFGTemplate.txt',\n",
    "                    popDir = 'PatchFlow_data/day2/',\n",
    "                    populationPattern = '*population.patchsim',\n",
    "                    networkPattern = '/*aggregate.patchsim',\n",
    "                    explicitDirectories = True,\n",
    "                    stubFile='templates/RunSimTemplate1Rep.py',\n",
    "                    setupFile='ExperimentSetupHP.csv'):\n",
    "    \"\"\"One and done prep all experiments function\"\"\"\n",
    "    \n",
    "    USANetwork = popDir + '/USA_config_min_5_max_100_alpha_400_day2_with_IATA_and_commuters.patchsim'\n",
    "    populations = sorted(glob(popDir+populationPattern))\n",
    "    networks = [USANetwork]+sorted(glob(popDir+networkPattern))\n",
    "    \n",
    "    matched = alignPopNets(populations,networks)\n",
    "    scenarioLinesDict,scenarioEventsDict = getScenarioLines(setupFile)\n",
    "    \n",
    "    with open(template) as templateIn:\n",
    "        templateLines = templateIn.readlines()\n",
    "        \n",
    "    if explicitDirectories:\n",
    "        cwd = os.getcwd()+'/'\n",
    "    else:\n",
    "        cwd = ''\n",
    "    if prefix != '':\n",
    "        prefix = prefix+'_'\n",
    "    \n",
    "    for experimentName, (population,network) in matched.items():\n",
    "        experimentMetaData = []\n",
    "        header = ['### TEMPLATE LINES\\n\\n']\n",
    "        separator = ['\\n\\n\\n### EXPERIMENT PREP LINES\\n\\n']\n",
    "        if experimentName in toRun:\n",
    "            for scenario, scenarioLines in scenarioLinesDict.items():\n",
    "                experimentNameOut = '%s%s/%s' % (prefix,experimentName,scenario)\n",
    "                linesOut = header+templateLines+separator+scenarioLines\n",
    "                \n",
    "                scenarioName = experimentNameOut.split('/')[-1]\n",
    "                scenarioEvents = scenarioEventsDict[scenarioName]\n",
    "                epidemic = scenarioEvents[0]\n",
    "                if scenarioEvents != [epidemic]:\n",
    "                    interventions = scenarioEvents[1:]\n",
    "                else:\n",
    "                    interventions = ['']\n",
    "                    \n",
    "                prefixLines = ['### EXPERIMENT FLAGS ITERATION\\n\\nflags = %s\\n\\n### EXPERIMENT EXECUTION STUB\\n\\n' % str(set(scenarioEvents))]\n",
    "                \n",
    "                prepExperiment(experimentNameOut,\n",
    "                               population,\n",
    "                               network,\n",
    "                               linesOut,\n",
    "                               stubFile,\n",
    "                               prefixLines)\n",
    "                \n",
    "                experimentMeta = {'Name':experimentNameOut.split('/')[-2],\n",
    "                                  'Scenario':scenarioName,\n",
    "                                  'Epidemic':epidemic,\n",
    "                                  'Interventions':' '.join(interventions),\n",
    "                                  'ConfigFile':'%sexperiments/%s/config.patchsim' % (cwd,experimentNameOut),\n",
    "                                  'RunScript':'%sexperiments/%s/RunPatchsim.py' % (cwd,experimentNameOut),\n",
    "                                  'PopulationFile':population,\n",
    "                                  'Network':network,\n",
    "                                  'MergedOutput':'%sexperiments/%s/MergedSamples.csv' % (cwd,experimentNameOut)}\n",
    "                experimentMetaData.append(experimentMeta)\n",
    "    \n",
    "            metaDataDf = pd.DataFrame(experimentMetaData)\n",
    "            print('experiments/%s%s/MetaData.csv' % (prefix,experimentName))\n",
    "            metaDataFileOut = 'experiments/%s%s/MetaData.csv' % (prefix,experimentName)\n",
    "            metaDataDf.to_csv(metaDataFileOut,index=False)\n",
    "    print(\"Writing experiment metadata to\", metaDataFileOut)\n",
    "\n",
    "    \n",
    "def getRunScript(metaDataRef,\n",
    "                   multiThread=False,\n",
    "                   asScript=True,\n",
    "                   skip=set(),\n",
    "                   nScripts=4):\n",
    "    \"\"\"Loads meta data and runs all experiments\"\"\"\n",
    "    meta = pd.read_csv(metaDataRef)\n",
    "    startDir = os.getcwd()\n",
    "    runScripts = meta.RunScript\n",
    "    script = []\n",
    "    for runScript in runScripts:\n",
    "        cell = runScript.split('/')[-2]\n",
    "        runDir = '/'.join(runScript.split('/')[:-1])\n",
    "        scriptCmd = 'python %s' % runScript.split('/')[-1]\n",
    "        os.chdir(runDir)\n",
    "        if not cell in script:\n",
    "            if asScript:\n",
    "                script.append('cd %s' % runDir)\n",
    "                script.append(\"echo 'Running cell %s'\" % cell)\n",
    "                script.append(scriptCmd)\n",
    "            else:\n",
    "                print(\"Running scenario %s\" % cell)\n",
    "                if multiThread:\n",
    "                    subprocess.Popen(scriptCmd.split())\n",
    "                else:\n",
    "                    subprocess.call(scriptCmd, shell=True)\n",
    "        else:\n",
    "            print(\"Skipping\",cell)\n",
    "            \n",
    "    os.chdir(startDir)\n",
    "    if script != []:\n",
    "        scriptRef = metaDataRef.replace('MetaData.csv','RunAll.sh')\n",
    "        print(\"Writing script to\", scriptRef)\n",
    "        scriptTxt = '\\n'.join(script)\n",
    "        with open(scriptRef,'w') as scriptOut:\n",
    "            scriptOut.write(scriptTxt)\n",
    "        if nScripts != 1:\n",
    "            chunkedScripts = [script[i:i+3] for i in range(0,len(script),3)]\n",
    "            nCells = len(chunkedScripts)\n",
    "            for i in range(nScripts):\n",
    "                subScriptTxt = '\\n'.join(['\\n'.join(chunkedScripts[i+j]) for j in range(0,nCells-1,nScripts)])\n",
    "                subScriptRef = scriptRef.replace('.sh',f'{i}.sh')\n",
    "                with open(subScriptRef,'w') as scriptOut:\n",
    "                    scriptOut.write(subScriptTxt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment generation and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RL Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_01\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_02\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_03\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_04\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_05\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_06\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_07\n",
      "Prepping experiment in directory WorkingTemplate2009v15_USA/RL_08\n",
      "experiments/WorkingTemplate2009v15_USA/MetaData.csv\n",
      "Writing experiment metadata to experiments/WorkingTemplate2009v15_USA/MetaData.csv\n",
      "Writing script to experiments/WorkingTemplate2009v15_USA/RunAll.sh\n"
     ]
    }
   ],
   "source": [
    "prepExperiments(prefix='WorkingTemplate2009v15',\n",
    "               template='templates/WorkingCFGTemplate.txt',\n",
    "               stubFile='templates/RunSimTemplate2009v15.py',\n",
    "               setupFile='ExperimentSetup2009.csv')\n",
    "\n",
    "getRunScript('experiments/WorkingTemplate2009v15_USA/MetaData.csv',nScripts=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HP Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_01\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_02\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_03\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_04\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_05\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_06\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_07\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_08\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_09\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_10\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_11\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_12\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_13\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_14\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_15\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_16\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_17\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_18\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_19\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_20\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_21\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_22\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_23\n",
      "Prepping experiment in directory WorkingTemplateP9_USA/HP_24\n",
      "experiments/WorkingTemplateP9_USA/MetaData.csv\n",
      "Writing experiment metadata to experiments/WorkingTemplateP9_USA/MetaData.csv\n",
      "Writing script to experiments/WorkingTemplateP9_USA/RunAll.sh\n"
     ]
    }
   ],
   "source": [
    "prepExperiments(prefix='WorkingTemplateP9',\n",
    "               template='templates/WorkingCFGTemplate.txt',\n",
    "               stubFile='templates/HP02RandomPopCalib.py')\n",
    "\n",
    "getRunScript('experiments/WorkingTemplateP9_USA/MetaData.csv',\n",
    "              multiThread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-geopandas]",
   "language": "python",
   "name": "conda-env-.conda-geopandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
